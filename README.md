# verizon-ai-studio-project

Project Overview:
This project involved a supervised classification challenge, where we worked with labeled data in order to classify positive and negative review sentiments. 
The data we worked with was public domain data in csv format. Our team found it particularly interesting to analyze how different models performed on the data.


Goals:
Our goal was to understand customer sentiment toward telecommunication brands in the US.
We expected to visualize key insights into the factors that play into customer sentiments, and how to improve based on these insights.
We worked using methods such as the DCC approach, data cleaning, and web scraping. We used tools such as pre-trained LLMs and several Python libraries for data visualization.


Business Impact:

Improved Customer Experience-
Understanding specific areas of feedback can help address issues early and tailor services to prevent customer churning.

Predictive Insights-
Identifying patterns of dissatisfaction can help predict potential churning, allowing for proactive measures to be taken.

and Competitive Advantage-
Predicting negative feedback and repairing these areas can help strengthen customer relationships and maintain a positive brand image.

Methodology:
Data Collection and Preprocessing: Downloaded the data; handled missing values and outliers; and performed exploration, tokenization, and feature engineering.

LLM Model Selection: Researched models, compared performances, and selected the most suitable LLM model.

Fine-Tuning and Fitting Model to DataL Trained the models using a preprocessed dataset and fine-tuned parameters for optimal performance.

Sentiment Analysis: Trained the models to classify sentiment as positive or negative.

Evaluation and Optimization: Assessed model performances and improved results based on evaluative measures.

Derive Insights and Visualize Results: Visualized results through plots and charts, and documented findings.


Results and Key Findings:
 
![image](https://github.com/user-attachments/assets/a84c332e-92cd-453f-92d8-306bc5657a2f)


LaMa deemed the best performing model
It has the best balance of high accuracy and low log loss.
While not the fastest, LaMa still has a reasonable runtime.


Visualizations:
![image](https://github.com/user-attachments/assets/7eb0fe7c-91db-4de6-a20c-54e07042c54d)


Potential Next Steps:
Continue model evaluation with further hyperparameter tuning.
Experiment with new LLM models.
Incorporate additional datasets for new training data.
Combine model performances with ensemble methods.


Individual contributions: performed data cleaning and exploration, LLM research and selection, model parameter tuning, LLM sentiment analysis training, model evaluations and optimizations, and mapped visualizations. 


